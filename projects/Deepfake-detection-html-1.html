<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Adversarially Robust Deepfake Detection</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="A compact, adversarially hardened deepfake detector built with a hybrid EfficientNet plus Vision Transformer architecture and a dual-attacker training protocol." />
  <style>
    :root{
      /* Light, warm palette like tashrifwala.com */
      --bg:#fbf8f2;           /* warm off white page background */
      --card:#ffffff;         /* card surface */
      --ink:#0f172a;          /* near black text */
      --muted:#64748b;        /* muted text */
      --border:#e6e8ec;       /* soft border */
      --chip:#f6f7fb;         /* subtle chip bg */
      --code:#f7f7fb;

      /* Primary actions like "View Projects" */
      --primary:#2140ff;      /* cobalt blue */
      --primary-hover:#1735d1;
      --ring: rgba(33, 64, 255, 0.18);
    }

    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0; background:var(--bg); color:var(--ink);
      font:16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,"Helvetica Neue",Arial;
      -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale;
    }

    .container{max-width:1100px; margin:0 auto; padding:24px}

    header{
      position:sticky; top:0; z-index:50;
      backdrop-filter:saturate(1.1) blur(6px);
      background:rgba(251,248,242,0.8);
      border-bottom:1px solid var(--border);
    }
    .header-inner{display:flex; align-items:flex-start; gap:16px; padding:12px 24px; max-width:1100px; margin:0 auto; flex-wrap:wrap}
    .logo{display:flex; align-items:center; gap:10px; text-decoration:none; color:var(--ink)}
    .logo-mark{width:36px; height:36px; border-radius:10px; background:var(--primary); box-shadow:0 6px 20px var(--ring)}
    .logo h1{font-size:18px; margin:0}
    .header-content{display:flex; flex-direction:column; gap:12px}
    .header-actions{display:flex; flex-wrap:wrap; gap:12px; margin-left:0px}
    @media(max-width:600px){ .header-actions{margin-left:0} }

    .pill{
      padding:10px 16px; border-radius:999px; text-decoration:none; font-weight:600; display:inline-flex; align-items:center; gap:10px;
      transition:transform .05s ease, box-shadow .2s ease, background-color .2s ease, color .2s ease, border-color .2s ease;
      box-shadow:0 8px 20px var(--ring);
      border:1px solid transparent;
    }
    .pill.primary{background:var(--primary); color:#fff}
    .pill.primary:hover{background:var(--primary-hover); transform:translateY(-1px)}
    .pill.ghost{background:#fff; color:var(--ink); border-color:var(--border); box-shadow:none}
    .pill.ghost:hover{background:#fafbff; transform:translateY(-1px); border-color:#d9dce3}

    main{padding:24px}

    section{background:var(--card); border:1px solid var(--border); border-radius:16px; padding:22px}
    .synopsis h2{margin:0 0 10px 0}
    h2{margin:0 0 12px; font-size:24px}
    h3{margin:16px 0 8px; font-size:18px}
    p{margin:10px 0}

    .chips{display:flex; flex-wrap:wrap; gap:8px; margin-top:8px}
    .chip{background:var(--chip); border:1px solid var(--border); padding:6px 10px; border-radius:999px; font-size:13px; color:var(--muted)}

    .grid{display:grid; gap:18px}
    @media(min-width:980px){ .grid{grid-template-columns: 280px 1fr} }
    nav.toc{
      position:sticky; top:76px; align-self:start; background:var(--card); border:1px solid var(--border); border-radius:14px; padding:14px;
    }
    nav.toc h3{margin:6px 6px 10px 6px; font-size:13px; color:var(--muted); letter-spacing:.4px; text-transform:uppercase}
    nav.toc a{
      display:block; color:var(--ink); text-decoration:none; padding:8px 10px; border-radius:10px; font-size:14px; border:1px solid transparent;
    }
    nav.toc a:hover{background:#f7f8ff; border-color:var(--border)}

    .callout{padding:12px 14px; border-left:4px solid var(--primary); background:#f3f5ff; border-radius:10px}

    table{width:100%; border-collapse:separate; border-spacing:0; overflow:hidden; border-radius:12px; margin:10px 0}
    thead th{background:#f6f7fb; color:var(--muted); font-weight:600; text-align:left; padding:10px; border-bottom:1px solid var(--border)}
    tbody td{padding:10px; border-bottom:1px solid var(--border)}
    tbody tr:hover td{background:#fafbff}

    footer{color:var(--muted); text-align:center; padding:36px 0}
    a{color:var(--primary)}
    .small{font-size:13px; color:var(--muted)}
    .badge{display:inline-flex; align-items:center; gap:8px; background:#f6f7fb; padding:8px 12px; border-radius:12px; border:1px solid var(--border)}
  </style>
</head>
<body>
  <header>
    <div class="header-inner">
      <div class="header-content">
        <a class="logo" href="#">
          <h1>Adversarially Robust Deepfake Detection</h1>
        </a>
        <div class="header-actions">
          <!-- keep this href pointing to your report file -->
          <a class="pill primary" href="../assets/Adversarially%20Robust%20Deepfake%20Detection-FINAL.pdf" download>
            ‚¨áÔ∏è Download the full report
            <small>(PDF)</small>
          </a>
          <a class="pill ghost" href="https://github.com" target="_blank" rel="noreferrer">
            üîó View project on GitHub
          </a>
        </div>
      </div>
      <div style="flex:1"></div>
    </div>
  </header>

  <main class="container">
    <section class="synopsis" id="synopsis">
      <h2>Synopsis</h2>
      <p>
        This project investigates a compact deepfake detector that remains reliable under adversarial manipulation. We propose a hybrid architecture combining an EfficientNet backbone with a small Vision Transformer head and train it using a dual attacker regime. One attacker is projected gradient descent, while the other is a tiny U Net that learns subtle, realistic perturbations shaped by total variation and frequency losses. We train on FaceForensics plus plus crops and evaluate cross dataset on Celeb DF v2. On clean inputs, the robust model matches a standard baseline, and under a combined learned attack with compression it attains a higher true positive rate at 1 percent false positive rate, a regime critical for high precision scenarios. Grad CAM analyses further indicate that the robust model attends to broader facial cues rather than narrow edge artifacts, aligning with its improved resilience.
      </p>

      <!-- Metric boxes under Synopsis were removed -->
      <div class="chips" aria-label="Key tags">
        <span class="chip">EfficientNet + ViT</span>
        <span class="chip">PGD + Learned U Net attacker</span>
        <span class="chip">TV and frequency constraints</span>
        <span class="chip">FaceForensics++ train</span>
        <span class="chip">Celeb DF v2 test</span>
        <span class="chip">Grad CAM explainability</span>
      </div>
    </section>

    <div class="grid" style="margin-top:18px">
      <nav class="toc" aria-label="Table of contents">
        <h3>Contents</h3>
        <a href="#problem">1. Problem the product solves</a>
        <a href="#solution">2. Solution overview</a>
        <a href="#architecture">3. Architecture</a>
        <a href="#attackers">4. Adversarial training</a>
        <a href="#data">5. Data pipeline and setup</a>
        <a href="#evaluation">6. Evaluation protocol</a>
        <a href="#results">7. Results at a glance</a>
        <a href="#explain">8. Explainability insights</a>
        <a href="#limits">9. Limits and future work</a>
        <a href="#faq">FAQ</a>
      </nav>

      <div class="content">
        <section id="problem">
          <h2>1. Problem the product solves</h2>
          <p>
            Deepfake media is now highly realistic. Detectors trained only for accuracy on clean benchmarks can fail when an attacker adds tiny, crafted perturbations or when common compressions wash away local artifacts. This product focuses on resilience. The aim is to keep detection performance usable even when inputs are manipulated to evade the model or passed through lossy compression.
          </p>
          <div class="callout">
            The north star metric is recall at very low false positive rates. We target higher TPR at 1 percent FPR under realistic attack plus compression.
          </div>
        </section>

        <section id="solution">
          <h2>2. Solution overview</h2>
          <p>
            We harden a compact hybrid detector through a game between the model and two complementary attackers. The network faces PGD noise and a learned U Net attacker that produces realistic, spatially smooth, compression resilient patterns. The U Net is leashed by total variation loss to reduce high frequency speckle and by a frequency domain loss that discourages very low frequency energy. The result is an attacker that searches mid to high frequency space and forces the detector to learn more stable cues.
          </p>
          <div class="chips">
            <span class="chip">Compact model</span>
            <span class="chip">Dual attacker training</span>
            <span class="chip">Compression aware robustness</span>
          </div>
        </section>

        <section id="architecture">
          <h2>3. Architecture</h2>
          <h3>3.1 EfficientViT detector</h3>
          <p>
            The backbone is EfficientNet B0 used as a feature extractor that outputs a 7 by 7 by 1280 map for a 224 by 224 face crop. We reshape this grid into 49 tokens, prepend a CLS token, add learnable positions, and pass the sequence through a small Transformer encoder with 4 layers and 4 heads. The CLS output goes into a light MLP head for binary classification.
          </p>
          <div class="chips">
            <span class="chip">EfficientNet B0 features</span>
            <span class="chip">ViT encoder, 4 layers</span>
            <span class="chip">MLP head</span>
          </div>
          <h3>3.2 Why hybrid</h3>
          <p>
            CNNs capture local texture tells like edge inconsistencies. Transformers capture long range relations like lighting agreement between forehead and jaw. Together they cover both local and global cues with a small parameter budget.
          </p>
        </section>

        <section id="attackers">
          <h2>4. Adversarial training</h2>
          <h3>4.1 PGD attacker</h3>
          <p>
            We use L infinity PGD with epsilon 8 over 255, step 2 over 255, and 10 iterations. Random start is included. This gives a strong baseline adversary that finds harmful pixel level changes.
          </p>
          <h3>4.2 Learned U Net attacker</h3>
          <p>
            A tiny U Net takes the clean face crop and outputs a perturbation delta bounded in L infinity by epsilon through a tanh gate and scaling. The U Net tries to maximize detector loss while obeying realism constraints.
          </p>
          <h3>4.3 Realism constraints</h3>
          <ul>
            <li><strong>Total variation loss</strong> promotes spatial smoothness, which avoids speckle like artifacts.</li>
            <li><strong>Frequency loss</strong> penalizes very low frequency energy in the perturbation spectrum, which nudges the attacker toward mid to high frequency patterns that often survive compression.</li>
          </ul>
          <h3>4.4 Training loop</h3>
          <p>
            For each batch we compute clean loss, PGD loss, update the U Net with its composite attacker loss, then update the detector on a fresh U Net perturbation. The detector minimizes the sum of clean, PGD, and U Net losses. Gradient clipping and mixed precision keep the dynamics stable.
          </p>
          <div class="callout">
            The arms race pushes the detector to stop over relying on a single brittle cue and to combine broader evidence across the face.
          </div>
        </section>

        <section id="data">
          <h2>5. Data pipeline and setup</h2>
          <p>
            We extract frames from FaceForensics plus plus c23 and Celeb DF v2, detect faces with MTCNN, then align and crop to 224 by 224. Training uses a subset of FF plus plus frames. Evaluation uses clean and attacked crops from Celeb DF v2 for cross dataset testing. Preprocessing uses resizing and ImageNet normalization. Training runs on a T4 GPU with AMP.
          </p>
          <div class="chips">
            <span class="chip">FF++ c23 train</span>
            <span class="chip">Celeb DF v2 test</span>
            <span class="chip">MTCNN face crops</span>
            <span class="chip">AMP enabled</span>
          </div>
        </section>

        <section id="evaluation">
          <h2>6. Evaluation protocol</h2>
          <p>
            We compare a baseline model trained on clean data and a robust model trained with the dual attacker loop. We test clean, JPEG quality 50, an H.264 like simulation, PGD white box, learned U Net, and the combined U Net plus compression settings. We report accuracy, ROC AUC, and TPR at 1 percent FPR. The last metric is the operational focus.
          </p>
          <div class="chips">
            <span class="chip">Clean</span>
            <span class="chip">JPEG 50</span>
            <span class="chip">H.264 like</span>
            <span class="chip">PGD</span>
            <span class="chip">Learned U Net</span>
            <span class="chip">U Net + compression</span>
          </div>
        </section>

        <section id="results">
          <h2>7. Results at a glance</h2>

          <h3>7.1 Cross domain performance on Celeb DF v2</h3>
          <table aria-label="Celeb DF v2 summary">
            <thead>
              <tr>
                <th>Scenario</th>
                <th>Accuracy (Base)</th>
                <th>Accuracy (Robust)</th>
                <th>AUC (Base)</th>
                <th>AUC (Robust)</th>
                <th>TPR@1% FPR (Base)</th>
                <th>TPR@1% FPR (Robust)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Clean</td><td>0.624</td><td>0.617</td><td>0.678</td><td>0.676</td><td>1.4%</td><td>1.2%</td>
              </tr>
              <tr>
                <td>JPEG 50</td><td>0.625</td><td>0.641</td><td>0.672</td><td>0.681</td><td>2.3%</td><td>2.3%</td>
              </tr>
              <tr>
                <td>H.264 like</td><td>0.636</td><td>0.661</td><td>0.693</td><td>0.703</td><td>2.2%</td><td>2.4%</td>
              </tr>
              <tr>
                <td>PGD white box</td><td>0.467</td><td>0.476</td><td>0.460</td><td>0.483</td><td>0.1%</td><td>0.1%</td>
              </tr>
              <tr>
                <td>Learned U Net</td><td>0.619</td><td>0.607</td><td>0.675</td><td>0.674</td><td>1.5%</td><td>1.5%</td>
              </tr>
              <tr>
                <td>U Net + JPEG 50</td><td>0.625</td><td>0.647</td><td>0.675</td><td>0.685</td><td>2.0%</td><td>2.9%</td>
              </tr>
              <tr>
                <td>U Net + H.264 like</td><td>0.644</td><td>0.654</td><td>0.690</td><td>0.699</td><td>2.5%</td><td>3.0%</td>
              </tr>
            </tbody>
          </table>

          <h3>7.2 In domain performance on FF plus plus c23</h3>
          <p class="small">
            Both models are near perfect on clean FF plus plus frames. Under compression the robust model shows a small edge in TPR at 1 percent FPR.
          </p>
          <table aria-label="FF++ c23 summary">
            <thead>
              <tr>
                <th>Scenario</th>
                <th>Accuracy (Base)</th>
                <th>Accuracy (Robust)</th>
                <th>AUC (Base)</th>
                <th>AUC (Robust)</th>
                <th>TPR@1% FPR (Base)</th>
                <th>TPR@1% FPR (Robust)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Clean</td><td>0.999</td><td>0.998</td><td>~1.000</td><td>~1.000</td><td>100%</td><td>100%</td>
              </tr>
              <tr>
                <td>JPEG 50</td><td>0.851</td><td>0.836</td><td>0.922</td><td>0.916</td><td>34.4%</td><td>38.7%</td>
              </tr>
              <tr>
                <td>H.264 like</td><td>0.912</td><td>0.912</td><td>0.965</td><td>0.962</td><td>64.1%</td><td>67.1%</td>
              </tr>
            </tbody>
          </table>
        </section>

        <section id="explain">
          <h2>8. Explainability insights</h2>
          <p>
            Grad CAM comparisons show that the baseline often fires on sharp borders like jawlines or the face boundary. The robust model spreads attention over cheeks and forehead, with less spill to background. This matches the idea that adversarial training discourages single cue dependence and pushes attention toward cues that are harder to scrub out with simple edits or compression.
          </p>
          <p>
            Thinking in frequency space helps. Baseline attention aligns with very high frequency details. The robust model raises sensitivity to mid frequency patterns and smooth shading consistency, which are more durable under compression and against small edits.
          </p>
        </section>

        <section id="limits">
          <h2>9. Limits and future work</h2>
          <ul>
            <li>Strong PGD still hurts both models on faces at this resolution. Larger models or stronger training schedules could help.</li>
            <li>Cross dataset AUC around the high 0.6s shows that generalization to harder fakes remains challenging.</li>
            <li>Temporal attacks are not modeled yet. Extending realism constraints to video time could improve resilience.</li>
          </ul>
        </section>

        <section id="faq">
          <h2>FAQ</h2>
          <h3>Why a tiny U Net attacker rather than only PGD</h3>
          <p>
            PGD is strong but often looks like fine noise. A learned U Net generates patterns that are spatially coherent and better mimic small cosmetic tweaks attackers might apply. This combination reduces overfitting to one attack style.
          </p>
          <h3>Why total variation and frequency constraints</h3>
          <p>
            TV lowers speckle, which makes perturbations more plausible. Penalizing very low frequency energy avoids broad washes that compression would flatten anyway. Together they push the attacker into the band where compression is less destructive and the detector must learn more durable cues.
          </p>
          <h3>Does the robust model hurt clean accuracy</h3>
          <p>
            On clean FF plus plus and clean Celeb DF v2, robust accuracy and AUC match the baseline within noise. The advantage shows up under attack and compression, which is where it matters operationally.
          </p>
        </section>
      </div>
    </div>

    <footer>
      <div class="badge">üìÑ Want the full write up</div>
      <div style="margin-top:10px">
        <a class="pill primary" href="Adversarially Robust Deepfake Detection-FINAL.pdf" download>Download the full report (PDF)</a>
      </div>
      <p class="small" style="margin-top:14px">
        Place this HTML file and the PDF in the same folder to enable direct download.
      </p>
    </footer>
  </main>
</body>
</html>

